{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "import csv\n",
    "import time\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load in the training data .csv file and convert it to a useable format\n",
    "# This cell should take about 3 minutes to run\n",
    "# Make sure the .csv file is in the same directory as this notebook!\n",
    "\n",
    "start_time = time.time()\n",
    "print \"Loading training data.\"\n",
    "\n",
    "train_data_raw = []\n",
    "\n",
    "with open(\"train.csv\") as train_csv:\n",
    "    reader = csv.reader(train_csv)\n",
    "\n",
    "    for row in reader:\n",
    "        train_data_raw.append(row)\n",
    "        \n",
    "print \"Training data loaded. Time Elapsed: %.0f seconds\" %(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Format the raw training data, and split it into training and dev data sets\n",
    "# This cell should take about 8 minutes to run\n",
    "\n",
    "start_time = time.time()\n",
    "print \"Formatting raw training data.\"\n",
    "\n",
    "# The data_size parameter can be adjusted in order to work with a subset of the training data\n",
    "data_size = len(train_data_raw)\n",
    "train_data, train_labels = [], []\n",
    "dev_data, dev_labels = [], []\n",
    "\n",
    "# Read through rows of raw training data   \n",
    "for i in range(1, data_size): \n",
    "    \n",
    "    # Add x, y, accuracy, and time columns to the training data\n",
    "    next_data = []\n",
    "    for j in range(1, 5): \n",
    "        next_data.append(float(train_data_raw[i][j]))\n",
    "    \n",
    "    # Add place_id to the training labels\n",
    "    next_label = train_data_raw[i][j]\n",
    "    \n",
    "    # Add the formatted rows to the training data/labels or dev data/labels\n",
    "    if (i > data_size/6):\n",
    "        train_data.append(next_data)\n",
    "        train_labels.append(next_label)\n",
    "    \n",
    "    else:\n",
    "        dev_data.append(next_data)\n",
    "        dev_labels.append(next_label)\n",
    "        \n",
    "print \"Raw training data formatted.\"\n",
    "print \"Time elapsed. %.0f seconds\" %(time.time() - start_time)\n",
    "print \"Training data size: %d\" %len(train_data)\n",
    "print \"Dev data size: %d\" %len(dev_data)\n",
    "print \"Number of distinct training labels: %d\" %len(set(train_labels))\n",
    "print \"Number of distinct dev labels: %d\" %len(set(dev_labels))\n",
    "labels_intersection = set(train_labels).intersection(dev_labels)\n",
    "print \"Number of dev labels not found in the training data: %d\" \\\n",
    "    %(len(dev_labels) - len(labels_intersection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocess training/dev data\n",
    "\n",
    "start_time = time.time()\n",
    "print \"Preprocessing training/dev data.\"\n",
    "\n",
    "train_data = scale(train_data)\n",
    "dev_data = scale(dev_data)\n",
    "\n",
    "print \"Training/dev data preprocessed. Time Elapsed: %.0f seconds\" %(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instantiate and train your model here...\n",
    "# See the example below\n",
    "k_neighbors_classifier = KNeighborsClassifier()\n",
    "k_neighbors_classifier.fit(train_data[:100], train_labels[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load/format/preprocess the test data .csv file\n",
    "# This cell should take about 12 minutes to run\n",
    "# It only needs to be run if we have a trained model that's ready to test\n",
    "# Make sure the .csv file is in the same directory as this notebook!\n",
    "\n",
    "start_time = time.time()\n",
    "print \"Loading/formatting/preprocessing test data.\"\n",
    "\n",
    "test_csv = open(\"test.csv\")\n",
    "reader = csv.reader(test_csv)\n",
    "\n",
    "test_data_raw = []\n",
    "\n",
    "for row in reader:\n",
    "    test_data_raw.append(row)\n",
    "\n",
    "# Read through rows of raw training data \n",
    "test_data = []\n",
    "for i in range(1, len(test_data_raw)):\n",
    "    \n",
    "    # Add x, y, accuracy, and time columns to the training data\n",
    "    next_row = []\n",
    "    for j in range(1, 5):\n",
    "        next_row.append(float(test_data_raw[i][j]))\n",
    "    \n",
    "    test_data.append(next_row)\n",
    "\n",
    "test_data = scale(test_data)\n",
    "print \"Test data loaded/formatted/preprocessed. Time Elapsed: %.0f seconds\" \\\n",
    "    %(time.time() - start_time)\n",
    "print \"Test data size: %d\" %len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Score your test data here using \"predict_proba\" and save the results under \"predictions\"\n",
    "# See the example below...\n",
    "\n",
    "predictions = k_neighbors_classifier.predict_proba(test_data[:100]) # Dummy variable for compilation purposes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print \"\\nExtracting the top 3 labels for each test data point.\"\n",
    "\n",
    "# We need a reference list of all possible labels in lexicographic order\n",
    "labels_sorted = list(set(train_labels))\n",
    "labels_sorted.sort()\n",
    "\n",
    "# Find the top 3 prediction probabilites for each test data point\n",
    "top_3_predictions = []\n",
    "for i in range(predictions.shape[0]):\n",
    "    \n",
    "    first_index = 0\n",
    "    second_index = 1\n",
    "    third_index = 2\n",
    "    \n",
    "    # Find the indices of the top 3 predictions based on the prediction probabilities\n",
    "    for j in range(predictions.shape[1]):\n",
    "        \n",
    "        if predictions[i][j] > predictions[i][first_index]:\n",
    "            third_index = second_index\n",
    "            second_index = first_index\n",
    "            first_index = j\n",
    "            \n",
    "        elif predictions[i][j] > predictions[i][second_index]:\n",
    "            third_index = second_index\n",
    "            second_index = j\n",
    "            \n",
    "        elif predictions[i][j] > predictions[i][third_index]:\n",
    "            third_index = j\n",
    "    \n",
    "    # Use those indices to find the actual values the predictions from our reference list\n",
    "    top_3_predictions.append([labels_sorted[first_index], labels_sorted[second_index], labels_sorted[third_index]])\n",
    "\n",
    "print \"Top 3 predictions made. Time elapsed: %.0f seconds\" %(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write the test predictions to the csv file\n",
    "# Make sure you have a file called \"submission.csv\" in the same file as this notebook!\n",
    "\n",
    "print \"Writing predictions to CSV file.\"\n",
    "start_time = time.time()\n",
    "\n",
    "with open('submission.csv', 'r+b') as submission:\n",
    "    submission_writer = csv.writer(submission, delimiter=',')\n",
    "    submission_writer.writerow(['row_id', 'place_id'])\n",
    "    \n",
    "    for i in range (predictions.shape[0]):\n",
    "        row_id = str(i)\n",
    "        place_ids = str(top_3_predictions[i][0]) + \" \" + str(top_3_predictions[i][1]) + \" \" + str(top_3_predictions[i][2])\n",
    "        submission_writer.writerow([row_id, place_ids])\n",
    "\n",
    "print \"Writing done. Time Elapsed: %.0f seconds\" %(time.time() - start_time)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
