{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import scale\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data.\n",
      "Training data loaded. Time Elapsed: 126 seconds\n"
     ]
    }
   ],
   "source": [
    "# Load in the training data .csv file and convert it to a useable format\n",
    "# This cell should take about 3 minutes to run\n",
    "start_time = time.time()\n",
    "print \"Loading training data.\"\n",
    "\n",
    "train_data_raw = []\n",
    "\n",
    "with open(\"train.csv\") as train_csv:\n",
    "    reader = csv.reader(train_csv)\n",
    "\n",
    "    for row in reader:\n",
    "        train_data_raw.append(row)\n",
    "        \n",
    "print \"Training data loaded. Time Elapsed: %.0f seconds\" %(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing training data.\n",
      "Training data preprocessed. Time Elapsed: 528 seconds\n",
      "Training data size: 29118021\n",
      "Number of distinct training labels: 108390\n"
     ]
    }
   ],
   "source": [
    "data_size = len(train_data_raw) # This parameter can be adjusted\n",
    "\n",
    "start_time = time.time()\n",
    "print \"Preprocessing training data.\"\n",
    "\n",
    "train_data = []\n",
    "train_labels = []\n",
    "#dev_data = []\n",
    "#dev_labels = []\n",
    "\n",
    "for i in range(1, data_size):\n",
    "    next_row = []\n",
    "    for j in range(1, 5):\n",
    "        next_row.append(float(train_data_raw[i][j]))\n",
    "    \n",
    "    train_data.append(next_row)\n",
    "    train_labels.append(train_data_raw[i][5])\n",
    "#    if (i > data_size/6):\n",
    "#        train_data.append(next_row)\n",
    "#        train_labels.append(train_data_raw[i][5])\n",
    "#    \n",
    "#    else:\n",
    "#        dev_data.append(next_row)\n",
    "#        dev_labels.append(train_data_raw[i][5])\n",
    "\n",
    "num_train_labels = len(set(train_labels))\n",
    "#num_dev_labels = len(set(dev_labels))\n",
    "#labels_intersection = set(train_labels).intersection(dev_labels)\n",
    "#dev_only_labels = num_dev_labels - len(labels_intersection)\n",
    "\n",
    "train_data = scale(train_data)\n",
    "#dev_data = scale(dev_data)\n",
    "\n",
    "print \"Training data preprocessed. Time Elapsed: %.0f seconds\" %(time.time() - start_time)\n",
    "print \"Training data size: %d\" %len(train_data)\n",
    "#print \"Dev data size: %d\" %len(dev_data)\n",
    "print \"Number of distinct training labels: %d\" %num_train_labels\n",
    "#print \"Number of distinct dev labels: %d\" %num_dev_labels\n",
    "#print \"Number of dev labels not found in the training data: %d\" %dev_only_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a KNN model.\n",
      "Model trained. Time elapsed: 2863 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train a knn model\n",
    "start_time = time.time()\n",
    "print \"Training a KNN model.\"\n",
    "k_neighbors_classifier = KNeighborsClassifier(n_neighbors = 10)\n",
    "k_neighbors_classifier.fit(train_data, train_labels)\n",
    "print \"Model trained. Time elapsed: %d seconds\" %(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading/formatting/preprocessing test data.\n",
      "Test data loaded/formatted/preprocessed Time Elapsed: 522 seconds\n"
     ]
    }
   ],
   "source": [
    "# Load in the test data .csv file and convert it to a useable format\n",
    "# This cell should take about 3 minutes to run \n",
    "# It only needs to be run if we have a trained model that's ready to test\n",
    "start_time = time.time()\n",
    "print \"Loading/formatting/preprocessing test data.\"\n",
    "\n",
    "test_csv = open(\"test.csv\")\n",
    "reader = csv.reader(test_csv)\n",
    "\n",
    "test_data_raw = []\n",
    "\n",
    "for row in reader:\n",
    "    test_data_raw.append(row)\n",
    "     \n",
    "test_data = []\n",
    "for i in range(1, len(test_data_raw)):\n",
    "    next_row = []\n",
    "    for j in range(1, 5):\n",
    "        next_row.append(float(test_data_raw[i][j]))\n",
    "    \n",
    "    test_data.append(next_row)\n",
    "\n",
    "test_data = scale(test_data)\n",
    "\n",
    "print \"Test data loaded/formatted/preprocessed Time Elapsed: %.0f seconds\" \\\n",
    "    %(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting possible labels.\n",
      "Labels sorted. Time elapsed: 18 seconds\n",
      "\n",
      "Predicting the test data.\n",
      "\n",
      "\n",
      "(100000 / 8607230) data points predicted after 981 seconds\n",
      "\n",
      "(200000 / 8607230) data points predicted after 1943 seconds\n",
      "\n",
      "(300000 / 8607230) data points predicted after 2907 seconds\n",
      "\n",
      "(400000 / 8607230) data points predicted after 3873 seconds\n",
      "\n",
      "(500000 / 8607230) data points predicted after 4834 seconds\n",
      "\n",
      "(600000 / 8607230) data points predicted after 5809 seconds\n",
      "\n",
      "(700000 / 8607230) data points predicted after 6771 seconds\n",
      "\n",
      "(800000 / 8607230) data points predicted after 7737 seconds\n",
      "\n",
      "(900000 / 8607230) data points predicted after 8700 seconds\n",
      "\n",
      "(1000000 / 8607230) data points predicted after 9664 seconds\n",
      "\n",
      "(1100000 / 8607230) data points predicted after 10627 seconds\n",
      "\n",
      "(1200000 / 8607230) data points predicted after 11590 seconds\n",
      "\n",
      "(1300000 / 8607230) data points predicted after 12561 seconds\n",
      "\n",
      "(1400000 / 8607230) data points predicted after 13523 seconds\n",
      "\n",
      "(1500000 / 8607230) data points predicted after 14492 seconds\n",
      "\n",
      "(1600000 / 8607230) data points predicted after 15452 seconds\n",
      "\n",
      "(1700000 / 8607230) data points predicted after 16415 seconds\n",
      "\n",
      "(1800000 / 8607230) data points predicted after 17377 seconds\n",
      "\n",
      "(1900000 / 8607230) data points predicted after 18342 seconds\n",
      "\n",
      "(2000000 / 8607230) data points predicted after 19304 seconds\n",
      "\n",
      "(2100000 / 8607230) data points predicted after 20270 seconds\n",
      "\n",
      "(2200000 / 8607230) data points predicted after 21233 seconds\n",
      "\n",
      "(2300000 / 8607230) data points predicted after 22198 seconds\n",
      "\n",
      "(2400000 / 8607230) data points predicted after 23203 seconds\n",
      "\n",
      "(2500000 / 8607230) data points predicted after 24268 seconds\n",
      "\n",
      "(2600000 / 8607230) data points predicted after 25327 seconds\n",
      "\n",
      "(2700000 / 8607230) data points predicted after 26379 seconds\n",
      "\n",
      "(2800000 / 8607230) data points predicted after 27425 seconds\n",
      "\n",
      "(2900000 / 8607230) data points predicted after 28511 seconds\n",
      "\n",
      "(3000000 / 8607230) data points predicted after 29588 seconds\n",
      "\n",
      "(3100000 / 8607230) data points predicted after 30707 seconds\n",
      "\n",
      "(3200000 / 8607230) data points predicted after 31837 seconds\n",
      "\n",
      "(3300000 / 8607230) data points predicted after 32937 seconds\n",
      "\n",
      "(3400000 / 8607230) data points predicted after 33931 seconds\n",
      "\n",
      "(3500000 / 8607230) data points predicted after 34903 seconds\n",
      "\n",
      "(3600000 / 8607230) data points predicted after 35890 seconds\n",
      "\n",
      "(3700000 / 8607230) data points predicted after 36847 seconds\n",
      "\n",
      "(3800000 / 8607230) data points predicted after 37809 seconds\n",
      "\n",
      "(3900000 / 8607230) data points predicted after 38774 seconds\n",
      "\n",
      "(4000000 / 8607230) data points predicted after 39729 seconds\n",
      "\n",
      "(4100000 / 8607230) data points predicted after 40687 seconds\n",
      "\n",
      "(4200000 / 8607230) data points predicted after 41709 seconds\n",
      "\n",
      "(4300000 / 8607230) data points predicted after 42685 seconds\n",
      "\n",
      "(4400000 / 8607230) data points predicted after 43647 seconds\n",
      "\n",
      "(4500000 / 8607230) data points predicted after 44621 seconds\n",
      "\n",
      "(4600000 / 8607230) data points predicted after 45581 seconds\n",
      "\n",
      "(4700000 / 8607230) data points predicted after 46541 seconds\n",
      "\n",
      "(4800000 / 8607230) data points predicted after 47504 seconds\n",
      "\n",
      "(4900000 / 8607230) data points predicted after 48469 seconds\n",
      "\n",
      "(5000000 / 8607230) data points predicted after 49436 seconds\n",
      "\n",
      "(5100000 / 8607230) data points predicted after 50403 seconds\n",
      "\n",
      "(5200000 / 8607230) data points predicted after 51368 seconds\n",
      "\n",
      "(5300000 / 8607230) data points predicted after 52335 seconds\n",
      "\n",
      "(5400000 / 8607230) data points predicted after 53300 seconds\n",
      "\n",
      "(5500000 / 8607230) data points predicted after 54270 seconds\n",
      "\n",
      "(5600000 / 8607230) data points predicted after 55238 seconds\n",
      "\n",
      "(5700000 / 8607230) data points predicted after 56205 seconds\n",
      "\n",
      "(5800000 / 8607230) data points predicted after 57164 seconds\n",
      "\n",
      "(5900000 / 8607230) data points predicted after 58122 seconds\n",
      "\n",
      "(6000000 / 8607230) data points predicted after 59078 seconds\n",
      "\n",
      "(6100000 / 8607230) data points predicted after 60036 seconds\n",
      "\n",
      "(6200000 / 8607230) data points predicted after 60994 seconds\n",
      "\n",
      "(6300000 / 8607230) data points predicted after 61950 seconds\n",
      "\n",
      "(6400000 / 8607230) data points predicted after 62906 seconds\n",
      "\n",
      "(6500000 / 8607230) data points predicted after 63864 seconds\n",
      "\n",
      "(6600000 / 8607230) data points predicted after 64823 seconds\n",
      "\n",
      "(6700000 / 8607230) data points predicted after 65785 seconds\n",
      "\n",
      "(6800000 / 8607230) data points predicted after 66741 seconds\n",
      "\n",
      "(6900000 / 8607230) data points predicted after 67702 seconds\n",
      "\n",
      "(7000000 / 8607230) data points predicted after 68663 seconds\n",
      "\n",
      "(7100000 / 8607230) data points predicted after 69620 seconds\n",
      "\n",
      "(7200000 / 8607230) data points predicted after 70576 seconds\n",
      "\n",
      "(7300000 / 8607230) data points predicted after 71538 seconds\n",
      "\n",
      "(7400000 / 8607230) data points predicted after 72494 seconds\n",
      "\n",
      "(7500000 / 8607230) data points predicted after 73452 seconds\n",
      "\n",
      "(7600000 / 8607230) data points predicted after 74409 seconds\n",
      "\n",
      "(7700000 / 8607230) data points predicted after 75370 seconds\n",
      "\n",
      "(7800000 / 8607230) data points predicted after 76329 seconds\n",
      "\n",
      "(7900000 / 8607230) data points predicted after 77289 seconds\n",
      "\n",
      "(8000000 / 8607230) data points predicted after 78252 seconds\n",
      "\n",
      "(8100000 / 8607230) data points predicted after 79513 seconds\n",
      "\n",
      "(8200000 / 8607230) data points predicted after 80477 seconds\n",
      "\n",
      "(8300000 / 8607230) data points predicted after 81443 seconds\n",
      "\n",
      "(8400000 / 8607230) data points predicted after 82411 seconds\n",
      "\n",
      "(8500000 / 8607230) data points predicted after 83378 seconds\n",
      "\n",
      "(8600000 / 8607230) data points predicted after 84343 seconds\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 30 is out of bounds for axis 0 with size 30",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-581ae1522aed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mnext_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_3_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 30 is out of bounds for axis 0 with size 30"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print \"Sorting possible labels.\"\n",
    "labels_sorted = list(set(train_labels))\n",
    "labels_sorted.sort()\n",
    "print \"Labels sorted. Time elapsed: %.0f seconds\" %(time.time() - start_time)\n",
    "\n",
    "def top_3_predictions(probabilities):\n",
    "    \n",
    "    probabilities = list(probabilities)\n",
    "    sorted_probabilities = list(probabilities)\n",
    "    sorted_probabilities.sort()\n",
    "    \n",
    "    first_index = probabilities.index(sorted_probabilities[len(sorted_probabilities) - 1])\n",
    "    second_index = probabilities.index(sorted_probabilities[len(sorted_probabilities) - 2])\n",
    "    third_index = probabilities.index(sorted_probabilities[len(sorted_probabilities) - 3])\n",
    "    \n",
    "    return [labels_sorted[first_index],labels_sorted[second_index],labels_sorted[third_index]]\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "print \"\\nPredicting the test data.\\n\"\n",
    "\n",
    "predictions = []\n",
    "\n",
    "batch_size = 100\n",
    "num_of_batches = int(np.ceil(len(train_data)/float(batch_size)))\n",
    "\n",
    "for i in range(num_of_batches):\n",
    "    \n",
    "    first_index = batch_size * i\n",
    "    last_index = batch_size * (i+1)\n",
    "    if last_index > len(test_data) - 1:\n",
    "        last_index = len(test_data) - 1\n",
    "        \n",
    "    probabilities = k_neighbors_classifier.predict_proba(test_data[first_index:last_index])\n",
    "    \n",
    "    for j in range(batch_size):\n",
    "        next_predictions = top_3_predictions(probabilities[j])\n",
    "        predictions.append(next_predictions)\n",
    "                \n",
    "    if (i+1) % 1000 == 0:\n",
    "        print \"(%d / %d) data points predicted after %.0f seconds\" \\\n",
    "            %(last_index, len(test_data), (time.time() - start_time))\n",
    "    \n",
    "print \"\\nTest data predicted. Time Elapsed: %.0f seconds\" %(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predictions to CSV file.\n",
      "Writing done. Time Elapsed: 34 seconds\n"
     ]
    }
   ],
   "source": [
    "print \"Writing predictions to CSV file.\"\n",
    "start_time = time.time()\n",
    "\n",
    "with open('submission.csv', 'r+b') as submission:\n",
    "    submission_writer = csv.writer(submission, delimiter=',')\n",
    "    submission_writer.writerow(['row_id', 'place_id'])\n",
    "    \n",
    "    for i in range (len(predictions)):\n",
    "        row_id = str(i)\n",
    "        place_ids = str(predictions[i][0]) + \" \" + str(predictions[i][1]) + \" \" + str(predictions[i][2])\n",
    "        submission_writer.writerow([row_id, place_ids])\n",
    "\n",
    "print \"Writing done. Time Elapsed: %.0f seconds\" %(time.time() - start_time)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
